---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a senior undergraduate student majoring in Artificial Intelligence at Northeastern University, China. Currently, I have been working as a Research Assistant under the supervision of [Prof. Mingyu Ding](https://dingmyu.github.io) at UNC-Chapel Hill and [Prof. Yao (Mark) Mu](https://yaomarkmu.github.io/) at [ScaleLab, SJTU](https://scalelab-sjtu.github.io/index.html). 


My research lies at the intersection of **embodied intelligence**, **multimodal reasoning**, and **human-robot interaction**. I am particularly interested in developing foundation models that ground **language and perception** in real-world physical understanding, enabling robots to reason, plan, and act effectively in complex environments.

* **Language Grounding and Spatial Manipulation:** Connecting structured representations with spatial reasoning and physically grounded robotic actions.
* **Egocentric Embodied Perception in MLLMs:** Studying how multimodal large language models perceive and interpret the world from an embodied, first-person perspective.
* **Multimodal Reasoning and Planning:** Enabling embodied agents to integrate vision, language, and action for structured decision-making and open-world generalization.
* **Human‚ÄìRobot Collaborative Intelligence:** Designing interactive systems that support safe and adaptive collaboration between humans and robots in real‚Äìsimulation hybrid environments.

Ultimately, my goal is to build **embodied agents that learn from real-world interactions**, developing **causal reasoning** and **compositional skills** for generalizable mobile manipulation. Guided by the principle of creating technology *with everyone, for everyone*, my research aims to advance **accessible, human-centered AI** that enhances daily life and broadens equitable access to intelligent systems.


<span style="color:blue; font-weight:bold">‚ú® I am looking for a Ph.D. position starting in 2026 Fall. Please feel free to reach out!</span>


## üìù Publications 
(*: equal contribution; ‚Ä†: corresponding author)


Ganlin Yang, Tianyi Zhang, Haoran Hao, Weiyun Wang, **Yibin Liu**, Dehui Wang, Guanzhou Chen, Zijian Cai, Junting Chen, Weijie Su, Wengang Zhou, Yu Qiao, Jifeng Dai, Jiangmiao Pang, Gen Luo, Wenhai Wang, Yao Mu‚Ä†, Zhi Hou‚Ä†. Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning. **arXiv 2025**. ([Paper](https://arxiv.org/pdf/2510.11027) / [Code](https://github.com/OpenGVLab/Vlaser?tab=readme-ov-file) / [Webpage](https://internvl.github.io/blog/2025-10-11-Vlaser/)) <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/OpenGVLab/Vlaser">


Tianxing Chen*, Zanxin Chen*, Baijun Chen*, Zijian Cai*, **Yibin Liu***, ... Ping Luo‚Ä†, Yao Mu‚Ä†. RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation. **arXiv 2025**. ([Paper](https://arxiv.org/pdf/2506.18088) / [Webpage](https://robotwin-platform.github.io) / [Repo](https://github.com/RoboTwin-Platform/RoboTwin)) <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/RoboTwin-Platform/RoboTwin">


Nan Gao‚Ä†, **Yibin Liu**, Xin Tang, Yanyan Liu, Chun Yu, Yun Huang, Yuntao Wang, Flora D. Salim, Xuhai Orson Xu, Jun Wei, Yuanchun Shi. The Homework Wars: Exploring Emotions, Behaviours, and Conflicts in Parent-Child Homework Interactions. **ACM IMWUT/UbiComp 2025**. ([Paper](https://arxiv.org/abs/2502.01325v2))

**Yibin Liu***, Zhixuan Liang*, Zanxing Chen*, Tianxing Chen, Mengkang Hu,
  Wanxi Dong, Congsheng Xu, Zhaoming Han, Yusen Qin, Yao Mu‚Ä†. HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents. **ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence**. ([Paper](https://arxiv.org/abs/2508.02629)/ [Code](https://github.com/NEUIR/Self-Guide))

**Yibin Liu**, Zhenghao Liu‚Ä†, Yukun Yan, Shi Yu, Shuo Wang, Liner Yang, Yu Gu, Ge Yu, Huimin Chen. Self-Guide: A LLM Reasoning Enhancement Method Based on Self-Guided Planning. **CCL 2024 / Journal of Chinese Information Processing**. ([Paper EN](https://github.com/10-OASIS-01/10-OASIS-01.github.io/blob/master/assets/_CCL2024__Self_Guide__A_LLM_Reasoning_Enhancement_Method_Based_on_Self_Guided_Planning_EN_-4.pdf) / [Paper CN](https://10-oasis-01.github.io/assets/183_self_guide_.pdf)/ [Code](https://robotwin-platform.github.io/doc/usage/expert-code-gen.html))

## üìñ Research Experiences


### **University of North Carolina at Chapel Hill ‚Äì Research Intern**

**Advisor:** [Prof. Mingyu Ding](https://dingmyu.github.io) ¬∑ üìÖ **June 2025 ‚Äì Present**, Remote

At UNC, I work on enhancing multimodal large language models (MLLMs) with **spatial understanding** and **action-level reasoning** for robotic manipulation, by leveraging **human language instructions** and **interactive guidance in augmented reality (AR) environments**. This research explores how embodied agents can better ground language in physical contexts to perform complex tasks more effectively.

### **Shanghai Jiao Tong University ‚Äì Research Assistant**

**Advisor:** [Prof. Yao Mu](https://yaomarkmu.github.io) ¬∑ üìÖ **March 2025 ‚Äì Present**, Shanghai, China

At SJTU, I serve as an equal first author and core contributor of **RoboTwin 2.0**, a scalable benchmark for robust bimanual robotic manipulation. I led the design and implementation of the **robot policy code generation agent**, providing the foundation for robust policy data generation in embodied agents.


### **Tsinghua University ‚Äì [Pervasive HCI Lab](https://pi.cs.tsinghua.edu.cn/) ‚Äì Research Assistant**

**Advisor:** [A/Prof Nan Gao](https://nancygao.com/), [A/Prof Chun Yu](https://pi.cs.tsinghua.edu.cn/lab/people/ChunYu/) ¬∑ üìÖ **June 2024 ‚Äì January 2025**, Beijing, China

At Tsinghua, I developed **LLM-based methods** to infer **human behaviors and mental states** from dialogue data, aiming to enhance self-awareness and promote well-being. I combined **LLM-driven analysis** with **expert qualitative coding** to process large-scale family education data and built a **recommendation system** that provides personalized guidance for parent‚Äìchild interactions.



## üè¢ Industry Experiences

### **Horizon Robotics ‚Äì Cloud Platform Intern**

**Mentor:** [Yusen Qin (VP of Technology, D-Robotics)](https://www.linkedin.com/in/yusen-qin-5b23345b/?originalSubdomain=cn) ¬∑ üìÖ **June 2025 ‚Äì Present**, Beijing, China ¬∑ Hybrid

At Horizon Robotics, I focus on the development of the **RDK-agent** . I am building an **LLM-powered Copilot system** within VSCode to support robotic system development, including **automatic coding, environment setup, test generation, code explanation, and manipulation data acquisition**, bridging cutting-edge language models with industrial-grade robotics development workflows.



## üí¨ Talks
- 2024.08, ‚ÄúRetrieval-Augmented Generation Modeling‚Äù for Mingtong Weilai (Beijing) Digital Health Science & Technology Research Institute.

## üë• Academic Service

- Co-Founder of [VapourX](https://vapour-x.cn), an open community for embodied AI beginners, enthusiasts, and researchers.

- Student Committee of [TriFusion Workshop @ SIGGRAPH Asia 2025](https://sa2025.siggraph.org/) ‚Äî *Towards Embodied Intelligence Across Humans, Avatars, and Humanoid Robotics* (responsible for workshop email communications).

- Contributor of [Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide) <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/TianxingChen/Embodied-AI-Guide">

- Reviewer for [Chinese CHI 2024](http://chchi.icachi.org/24/).
  
## üèÜ Awards

- 2025.07 Outstanding Poster at ChinaSI 2025 (**Ranking 1st among 61 posters**, RoboTwin 2.0).
- 2024.11 Outstanding Individual in Technological Innovation of Northeastern University.
- 2024.05 Finalist of Mathematical Contest in Modeling (MCM/ICM 2024, **Top 1.69% in 10,387 teams**).
- 2023.10 National Level Third Prize in 2023 RoboCup China Competition Simulation 3D League Simulation (RoboCup 2023).
- 2023.10 National Level Second Prize in 2023 FIRA SimuroSot China Competition (RoboCup 2023).
- 2023.11 Future Technology Taihu Scholarship.
- 2023.09 Excellent Student Scholarship in Northeastern University.


## üíª Projects

### **RDK Copilot: LLM-powered Development Copilot for Robotics at Horizon Robotics**
- Developed and deployed a **VSCode plugin** that assists robotic system development using LLMs. Supported features include automatic coding, environment setup, code completion, test generation, code explanation, and manipulation data acquisition.

### **[MinRL: Minimal, Clean Code for Reinforcement Learning](https://github.com/10-OASIS-01/minrl)**  <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/10-OASIS-01/minrl">
- **Recognized and pinned by [MathFoundationRL](https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning)**, the most popular RL course on Chinese platforms, under "Third-party code and materials."
  
### **[Bencao RAG Medical Intelligent Assistant](https://github.com/10-OASIS-01/BenCao_RAG)**
- Developed a medical knowledge question-answering system that integrates context awareness, internet access, knowledge graphs, and RAG method to provide accurate and personalized medical information.



## üõ†Ô∏è Technologies

**Languages:** Python, C++, C, HTML/CSS, JavaScript, Swift, SQL, MATLAB/Simulink, LaTeX

**Technologies:** PyTorch, Hugging Face, scikit-learn, ROS, OpenCV, NumPy, Git, RAG, Linux, SLAM, iOS Development (SwiftUI, UIKit), ARKit, RealityKit


---

*"Live, travel, adventure, bless, and don't be sorry.üåç‚ú®"* ‚Äî Jack Kerouac

<!--
---
permalink: /
title: "Yibin (L√©on) Liu"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

-->



