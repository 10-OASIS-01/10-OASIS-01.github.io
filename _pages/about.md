---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a senior undergraduate student majoring in Artificial Intelligence at Northeastern University, China. Currently, I have been working as a Research Assistant working on **Embodied AI, Spatial Intelligence and Robotics** under the supervision of [Prof. Mingyu Ding](https://dingmyu.github.io) at UNC-Chapel Hill and [Prof. Yao (Mark) Mu](https://yaomarkmu.github.io/) at [ScaleLab, SJTU](https://scalelab-sjtu.github.io/index.html). Meanwhile, I closely collaborate with [Zhixuan Liang](https://liang-zx.github.io/) from MMLab@HKU and [Weiliang Tang](https://cuhkwilliam.github.io) from CUHK.


My research interests mainly focus on:
- **Grounding language in spatial understanding and robotic manipulation**
- **Reasoning and planning in multi-modality and embodied AI systems**
- **Human-Robot Collaborative Interaction in Real-Simulation Hybrid Environments**

My long-term research goal is to develop embodied agents that learn from rich, physically-informed data gathered through real-world interaction. I am dedicated to imbuing these agents with the capacity for causal reasoning and sophisticated decision-making, enabling them to collaborate seamlessly and safely with humans. This pursuit is guided by a core principle: to create technology that is fundamentally **with everyone**, **for everyone**, ensuring that advancements in AI provide **accessible assistance** to people from all walks of life.

<span style="color:blue; font-weight:bold">‚ú® I am looking for a Ph.D. position starting in 2026 Fall. Please feel free to reach out!</span>


## üìù Publications 
(*: equal contribution; ‚Ä†: corresponding author)

Tianxing Chen\*, Zanxin Chen\*, Baijun Chen\*, Zijian Cai\*, **Yibin Liu***, ... Ping Luo‚Ä†, Yao Mu‚Ä†. RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation. **arXiv 2025**. ([Webpage](https://robotwin-platform.github.io) / [Repo](https://github.com/RoboTwin-Platform/RoboTwin)) <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/RoboTwin-Platform/RoboTwin">

Nan Gao‚Ä†, **Yibin Liu**, Xin Tang, Yanyan Liu, Chun Yu, Yun Huang, Yuntao Wang, Flora D. Salim, Xuhai Orson Xu, Jun Wei, Yuanchun Shi. The Homework Wars: Exploring Emotions, Behaviours, and Conflicts in Parent-Child Homework Interactions. **ACM IMWUT/UbiComp 2025**. ([Paper](https://arxiv.org/abs/2502.01325v2))

**Yibin Liu***, Zhixuan Liang*, Zanxing Chen*, Tianxing Chen, Mengkang Hu,
  Wanxi Dong, Congsheng Xu, Zhaoming Han, Yusen Qin, Yao Mu‚Ä†. HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents. **ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence**. ([Paper](https://arxiv.org/abs/2508.02629)/ [Code](https://github.com/NEUIR/Self-Guide))

**Yibin Liu**, Zhenghao Liu‚Ä†, Yukun Yan, Shi Yu, Shuo Wang, Liner Yang, Yu Gu, Ge Yu, Huimin Chen. Self-Guide: A LLM Reasoning Enhancement Method Based on Self-Guided Planning. **CCL 2024 / Journal of Chinese Information Processing**. ([Paper EN](https://github.com/10-OASIS-01/10-OASIS-01.github.io/blob/master/assets/_CCL2024__Self_Guide__A_LLM_Reasoning_Enhancement_Method_Based_on_Self_Guided_Planning_EN_-4.pdf) / [Paper CN](https://10-oasis-01.github.io/assets/183_self_guide_.pdf)/ [Code](https://robotwin-platform.github.io/doc/usage/expert-code-gen.html))

## üìñ Research Experiences

### **Northwestern University, USA ‚Äì [MLL Lab](https://mll-lab-nu.github.io)** 

**Advisor:** [Prof. Manling Li](https://limanling.github.io), üìÖ**July 2025 ‚Äì Present**

Embodied multimodal LLM agents (Ongoing).

### **Joint Research Internship ‚Äì UNC-Chapel Hill, Horizon Robotics, SJTU**  

**Advisor:** [Prof. Mingyu Ding (UNC)](https://dingmyu.github.io), [Yusen Qin (VP of D-Robotics)](https://www.linkedin.com/in/yusen-qin-5b23345b/?originalSubdomain=cn), [Prof. Yao Mu (SJTU)](https://yaomarkmu.github.io/), üìÖ**March 2025 ‚Äì Present**

In this joint internship, I am empowering multimodal large language models (MLLMs) with spatial understanding and action-level reasoning for robotic manipulation. My contributions include developing robotic behavior code generation pipelines in closed-loop physical simulation environments and creating an LLM-powered Copilot to assist robotic system development for Horizon Robotics.

### **Tsinghua University ‚Äì [Pervasive HCI Lab](https://pi.cs.tsinghua.edu.cn/)**

**Advisor:** [A/Prof Nan Gao](https://nancygao.com/), [A/Prof Chun Yu](https://pi.cs.tsinghua.edu.cn/lab/people/ChunYu/), üìÖ**June 2024 ‚Äì January 2025**


At Tsinghua, I developed LLM-based methods to infer human behaviors and mental states from dialogue data, aiming to enhance self-awareness and promote well-being. I combined LLM-driven analysis with expert qualitative coding to process real-world data and built a recommendation system for family education strategies.


### **Northeastern University, China**  

**Advisor:** [A/Prof Zhenghao Liu](https://edwardzh.github.io/), üìÖ**October 2023 ‚Äì April 2024**


My research here explored Retrieval-Augmented Generation (RAG) methods to address the knowledge needs of LLMs. I specifically investigated how self-generated common sense knowledge and reasoning instructions could improve the reasoning abilities of large language models.


## üí¨ Talks
- 2024.08, ‚ÄúRetrieval-Augmented Generation Modeling‚Äù for Mingtong Weilai (Beijing) Digital Health Science & Technology Research Institute.

## üë• Academic Service

- Contributor of [Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide) <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/TianxingChen/Embodied-AI-Guide">

- Reviewer for [Chinese CHI 2024](http://chchi.icachi.org/24/).
  
## üèÜ Awards

- 2024.11 Outstanding Individual in Technological Innovation of Northeastern University.
- 2024.05 Finalist of Mathematical Contest in Modeling / Interdisciplinary Contest in Modeling (MCM/ICM 2024, **Top 1.69% in 10,387 teams**).
- 2023.10 National Level Third Prize in 2023 RoboCup China Competition Simulation 3D League Simulation (RoboCup 2023).
- 2023.10 National Level Second Prize in 2023 FIRA SimuroSot China Competition (RoboCup 2023).
- 2023.11 Future Technology Taihu Scholarship
- 2023.09 Excellent Student Scholarship in Northeastern University

## üíª Projects

### **RDK Copilot: LLM-powered Development Copilot for Robotics at Horizon Robotics**
- Developed and deployed a **VSCode plugin** that assists robotic system development using LLMs. Supported features include automatic coding, environment setup, code completion, test generation, code explanation, and manipulation data acquisition.
- **Tools Used:** Python, TypeScript, VSCode Extension API, ROS

### **[MinRL: Minimal, Clean Code for Reinforcement Learning](https://github.com/10-OASIS-01/minrl)**  <img alt="GitHub repo stars" src="https://img.shields.io/github/stars/10-OASIS-01/minrl">
- **Recognized and pinned by [MathFoundationRL](https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning)**, the most popular RL course on Chinese platforms, under "Third-party code and materials."
- **Tools Used:** Python, PyTorch, pytest

### **[Bencao RAG Medical Intelligent Assistant](https://github.com/10-OASIS-01/BenCao_RAG)**
- Developed a medical knowledge question-answering system that integrates context awareness, internet access, knowledge graphs, and RAG method to provide accurate and personalized medical information.
- **Tools Used:** Python, RAG, LLM, LangChain, Streamlit, Neo4j, Knowledge Graph

## üõ†Ô∏è Technologies

**Languages:** Python, C++, C, HTML/CSS, JavaScript, Swift, SQL, MATLAB/Simulink, LaTeX

**Technologies:** PyTorch, Hugging Face, scikit-learn, ROS, OpenCV, NumPy, Git, RAG, Linux, SLAM


<!--
---
permalink: /
title: "Yibin (L√©on) Liu"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

-->



